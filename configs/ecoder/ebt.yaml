_target_: zatom.models.ecoders.ebt.EBT

encoder: ${encoder}

d_x: ${encoder.d_model}
d_model: 768 # 384, 768, 1024
num_layers: 12 # 12, 12, 24
nhead: 12 # 6, 12, 16
mcmc_num_steps: 1
mcmc_step_size: 3000
randomize_mcmc_num_steps: 2
randomize_mcmc_num_steps_min: 2
randomize_mcmc_step_size_scale: 2
num_datasets: 2
langevin_dynamics_noise: 0.0
clamp_futures_grad_max_change: 9.0
truncate_mcmc: true
clamp_futures_grad: false
no_mcmc_detach: true
no_langevin_during_eval: false
mcmc_step_size_learnable: false
randomize_mcmc_num_steps_final_landscape: false

_target_: zatom.models.encoders.transformer.TransformerEncoder

max_num_elements: 100
d_model: 512
nhead: 8
dim_feedforward: 2048
activation: "gelu"
dropout: 0.0
norm_first: true
bias: true
add_mask_atom_type: ${ebm_module.interpolant.corrupt}
num_layers: 8

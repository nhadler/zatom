"""Flow matching interpolants.

Adapted from:
    - https://github.com/carlosinator/tabasco
    - https://github.com/jasonkyuyim/multiflow
    - https://github.com/facebookresearch/all-atom-diffusion-transformer
"""

import copy
from abc import ABC, abstractmethod
from typing import Callable, List, Literal, Tuple

import torch
import torch.nn as nn
import torch.nn.functional as F
from tensordict import TensorDict
from torch import Tensor
from torch_geometric.data import Batch
from torch_geometric.utils import to_dense_batch

from zatom.flow.path import FlowPath
from zatom.utils.metric_utils import split_losses_by_time
from zatom.utils.tensor_utils import apply_mask, mask_and_zero_com
from zatom.utils.typing_utils import typecheck


class Interpolant(ABC):
    """Abstract base class for data-noise interpolation.

    Subclasses must implement four domain-specific operations:
    1. sample_noise():    Draw a noise tensor matching the data layout.
    2. create_path():     Build the interpolation path between two data points for a given time t.
    3. compute_loss():    Return a supervised loss for a model prediction along the path.
    4. step():            Advance the system one explicit-Euler step during sampling.

    All methods work on batched `TensorDict` objects; the data entry is accessed via
    `key` and its padding mask via `key_pad_mask`.

    Args:
        key: Key to the data object of interest in the passed batch TensorDict.
        key_pad_mask: Key to the padding mask in the batch TensorDict.
        loss_weight: Scalar weight applied to the computed loss.
        time_factor: Optional callable `f(t)` that rescales the per-sample loss as a
            function of the interpolation time `t`.
        sample_schedule: Optional schedule for sampling times during training.
            One of (`linear`, `power`, `log`).
    """

    @typecheck
    def __init__(
        self,
        key: str,
        key_pad_mask: str = "padding_mask",
        loss_weight: float = 1.0,
        time_factor: Callable | None = None,
        sample_schedule: Literal["linear", "power", "log"] = "linear",
    ):
        self.key = key
        self.key_pad_mask = key_pad_mask
        self.loss_weight = loss_weight
        self.time_factor = time_factor
        self.sample_schedule = sample_schedule

    @typecheck
    @abstractmethod
    def sample_noise(self, shape: torch.Size, pad_mask: Tensor) -> Tensor:
        """Draw a random noise tensor compatible with the data layout.

        Args:
            shape: Desired tensor shape, usually `batch[self.key].shape`.
            pad_mask: Boolean/int mask where 1 indicates padded positions; noise must be
                zeroed at these indices.

        Returns:
            Noise tensor of shape `shape` located on the same device as `pad_mask`.
        """
        pass

    @typecheck
    @abstractmethod
    def create_path(
        self, x_1: TensorDict, t: Tensor, x_0: TensorDict | None = None
    ) -> Tuple[Tensor, Tensor, Tensor]:
        """Construct the interpolation triple `(x_0, x_t, dx_t)` for time `t`.

        Args:
            x_1: TensorDict containing the reference data point at *t = 1*.
            t: Tensor of shape `(B,)` with interpolation times in `[0, 1]`.
            x_0: Optional TensorDict with a pre-sampled noise state; if `None` a new
                one is drawn via `sample_noise()`.

        Returns:
            * x_0: Initial noise state.
            * x_t: Interpolated state at time `t`.
            * dx_t: Velocity, typically `x_1 - x_0`.
        """
        pass

    @typecheck
    @abstractmethod
    def compute_loss(
        self, path: FlowPath, pred: TensorDict, compute_stats: bool = True
    ) -> Tuple[Tensor, dict]:
        """Return a supervised loss for a model prediction at time `t`.

        Args:
            path: FlowPath object generated by `create_path`.
            pred: TensorDict with model outputs that correspond to `path.x_1[self.key]`.
            compute_stats: If `True`, also compute and return auxiliary metrics.

        Returns:
            Scalar loss and a (possibly empty) statistics dictionary.
        """
        pass

    @typecheck
    @abstractmethod
    def step(self, batch_t: TensorDict, pred: TensorDict, t: TensorDict, dt: TensorDict) -> Tensor:
        """Advance the sample one explicit-Euler step along the reverse process.

        Args:
            batch_t: TensorDict with the current sample at time `t`.
            pred: Model prediction (same layout as `batch_t`) used to compute the
                velocity field.
            t: TensorDict `(B,)` with current times.
            dt: TensorDict of step sizes to advance.

        Returns:
            Updated data tensor corresponding to time `t + dt`.
        """
        pass


class DiscreteInterpolant(Interpolant):
    """Interpolant between two discrete distributions.

    Args:
        **kwargs: Forwarded to `Interpolant.__init__`.
    """

    @typecheck
    def __init__(self, **kwargs):
        super().__init__(**kwargs)
        self.ce_loss = nn.CrossEntropyLoss(reduction="none")

    @typecheck
    def sample_noise(self, shape: torch.Size, pad_mask: Tensor) -> Tensor:
        """Return uniformly random one-hot noise.

        Args:
            shape: Desired output shape `(â€¦, C)` where `C` equals the number of discrete categories.
            pad_mask: Padding mask; rows with 1s are ignored and set to zeros.

        Returns:
            One-hot encoded noise tensor on the same device as `pad_mask`.
        """
        x_0 = torch.randint(0, shape[-1], shape[:-1], device=pad_mask.device)
        x_0 = F.one_hot(x_0, num_classes=shape[-1])
        return x_0

    @typecheck
    def create_path(
        self, x_1: TensorDict, t: Tensor, x_0: TensorDict | None = None
    ) -> Tuple[Tensor, Tensor, Tensor]:
        """Create a path for a ground truth point and a time step.

        Args:
            x_1: TensorDict containing the reference data point at *t = 1*.
            t: Tensor of shape `(B,)` with interpolation times in `[0, 1]`.
            x_0: Optional TensorDict with a pre-sampled noise state; if `None` a new
                one is drawn via `sample_noise()`.

        Returns:
            * x_0: Initial noise state.
            * x_t: Interpolated state at time `t`.
            * dx_t: Velocity, typically `x_1 - x_0`.
        """
        if x_0 is None:
            x_0_tensor = self.sample_noise(x_1[self.key].shape, x_1[self.key_pad_mask])
        else:
            x_0_tensor = x_0[self.key]

        t = t.unsqueeze(-1)
        assert t.shape == (
            x_1[self.key].shape[0],
            1,
        ), f"t shape: {t.shape} != {(x_1[self.key].shape[0], 1)}"

        _corruption_prob = torch.rand(x_1[self.key].shape[:-1], device=x_1[self.key].device)
        corrupt_mask = (_corruption_prob > t).unsqueeze(-1).int()

        x_t = x_0_tensor * corrupt_mask + x_1[self.key] * (1 - corrupt_mask)

        dx_t = x_1[self.key] - x_0_tensor

        return x_0_tensor, x_t, dx_t

    @typecheck
    def compute_loss(
        self, path: FlowPath, pred: TensorDict, compute_stats: bool = False, eps: float = 1e-6
    ) -> Tuple[Tensor, dict]:
        """Cross-entropy loss between prediction and ground truth.

        Args:
            path: FlowPath from `create_path` (only `path.x_1` is required).
            pred: Model logits with shape `(B, N, C)`.
            compute_stats: Whether to return an empty stats dict (always empty here).
            eps: Small constant to avoid division by zero.

        Returns:
            Mean loss over molecules and an empty statistics dict.
        """
        real_mask = 1 - path.x_1[self.key_pad_mask].int()
        n_tokens = real_mask.sum(dim=-1)

        loss = self.ce_loss(pred[self.key].transpose(1, 2), path.x_1[self.key].argmax(dim=-1))
        per_mol_loss = (loss * real_mask).sum(dim=-1) / (n_tokens + eps)

        if self.time_factor:
            per_mol_loss = per_mol_loss * self.time_factor(path.t[self.key])

        loss_mask = real_mask.any(-1)
        avg_loss = per_mol_loss.sum() / (loss_mask.sum() + eps)

        total_loss = avg_loss * self.loss_weight

        stats_dict = {}
        return total_loss, stats_dict

    @typecheck
    def step(self, batch_t: TensorDict, pred: TensorDict, t: TensorDict, dt: TensorDict) -> Tensor:
        """Stochastic forward-Euler step for discrete states in continuous time.

        Args:
            batch_t: TensorDict containing one-hot states at time `t`.
            pred: Logits predicting the terminal distribution.
            t: TensorDict `(B,)` with current times.
            dt: TensorDict of step sizes to advance.

        Returns:
            One-hot tensor representing the new discrete state.
        """
        t = t[self.key].unsqueeze(-1).unsqueeze(-1)
        dt = dt[self.key].unsqueeze(-1).unsqueeze(-1)
        assert (
            dt.shape == t.shape == (batch_t[self.key].shape[0], 1, 1)
        ), f"t shape: {t.shape}, dt shape: {dt.shape}, batch_t shape: {batch_t[self.key].shape}"

        x1_probs = torch.nn.functional.softmax(pred[self.key], dim=-1)
        curr_state = batch_t[self.key].argmax(dim=-1)

        step_probs = ((dt / (1 - t)) * x1_probs).clamp(max=1.0)
        step_probs.scatter_(-1, curr_state[:, :, None], 0.0)
        step_probs.scatter_(-1, curr_state[:, :, None], 1.0 - step_probs.sum(dim=-1, keepdim=True))
        step_probs = step_probs.clamp(min=0.0)

        step_probs = step_probs / step_probs.sum(dim=-1, keepdim=True)

        x_next = torch.distributions.Categorical(step_probs).sample()
        x_next = F.one_hot(x_next, num_classes=batch_t[self.key].shape[-1])

        return x_next


class CenteredMetricInterpolant(Interpolant):
    """Linear interpolation between two points in Euclidean space.

    This class teaches the model to predict the endpoint of the path.

    Args:
        centered: If True, subtract center-of-mass so translation is ignored.
        scale_noise_by_log_num_tokens: Scale noise amplitude by `log(N_tokens)`.
        noise_scale: Standard deviation of the sampled Gaussian noise.
        **kwargs: Forwarded to `Interpolant.__init__`.
    """

    @typecheck
    def __init__(
        self,
        centered: bool = True,
        scale_noise_by_log_num_tokens: bool = False,
        noise_scale: float = 1.0,
        **kwargs,
    ):
        super().__init__(**kwargs)
        self.mse_loss = nn.MSELoss(reduction="none")
        self.centered = centered
        self.scale_noise_by_log_num_tokens = scale_noise_by_log_num_tokens
        self.noise_scale = noise_scale

        self.mask_fn = mask_and_zero_com if self.centered else apply_mask

    @typecheck
    def sample_noise(self, shape: torch.Size, pad_mask: Tensor) -> Tensor:
        """Return masked Gaussian noise with optional scaling.

        Args:
            shape: Desired output shape.
            pad_mask: Padding mask.

        Returns:
            Noise tensor.
        """
        x_0 = torch.randn(shape, device=pad_mask.device) * self.noise_scale

        if self.scale_noise_by_log_num_tokens:
            num_tokens = (~pad_mask).sum(dim=-1)
            x_0 = x_0 * torch.log(num_tokens[..., None, None])

        x_0 = self.mask_fn(x_0, pad_mask)

        return x_0

    @typecheck
    def create_path(
        self, x_1: TensorDict, t: Tensor, x_0: TensorDict | None = None
    ) -> Tuple[Tensor, Tensor, Tensor]:
        """Generate `(x_0, x_t, dx_t)` via linear interpolation in Euclidean space.

        Args:
            x_1: TensorDict containing the reference data point at *t = 1*.
            t: Tensor of shape `(B,)` with interpolation times in `[0, 1]`.
            x_0: Optional TensorDict with a pre-sampled noise state; if `None` a new
                one is drawn via `sample_noise()`.

        Returns:
            * x_0: Initial noise state.
            * x_t: Interpolated state at time `t`.
            * dx_t: Velocity, typically `x_1 - x_0`.
        """
        if x_0 is None:
            x_0_tensor = self.sample_noise(x_1[self.key].shape, x_1[self.key_pad_mask])
        else:
            x_0_tensor = x_0[self.key]

        t = t.unsqueeze(-1).unsqueeze(-1)
        assert t.shape == (
            x_1[self.key].shape[0],
            1,
            1,
        ), f"t shape: {t.shape} != {(x_1[self.key].shape[0], 1, 1)}"

        x_0_tensor = self.mask_fn(x_0_tensor, x_1[self.key_pad_mask])
        x_1_tensor = self.mask_fn(x_1[self.key], x_1[self.key_pad_mask])

        x_t = (1.0 - t) * x_0_tensor + t * x_1_tensor
        dx_t = x_1_tensor - x_0_tensor

        return x_0_tensor, x_t, dx_t

    @typecheck
    def compute_loss(
        self,
        path: FlowPath,
        pred: TensorDict,
        compute_stats: bool = True,
        pool_mask: bool = False,
        aux_mask: Tensor | None = None,
        eps: float = 1e-6,
    ) -> Tuple[Tensor, dict]:
        """Mean-squared error on masked continuous modalities with optional time weighting.

        Args:
            path: FlowPath containing the true states.
            pred: TensorDict with predicted states.
            compute_stats: Whether to compute and return statistics.
            pool_mask: If True, any-pool the real (i.e., non-padding) mask over the feature dimension.
            aux_mask: Optional mask tensor to apply to the loss calculation. Should be of shape
                `(batch_size, n_tokens)`.
            eps: Small constant to avoid division by zero.

        Returns:
            Total loss tensor.
        """
        real_mask = 1 - path.x_1[self.key_pad_mask].int()
        real_mask = real_mask.any(dim=-1, keepdim=True).int() if pool_mask else real_mask

        assert (
            aux_mask is None or aux_mask.shape == real_mask.shape
        ), f"aux_mask shape: {aux_mask.shape} != real_mask shape: {real_mask.shape}."

        real_mask = real_mask * aux_mask if aux_mask is not None else real_mask
        n_tokens = real_mask.sum(dim=-1)

        err = (pred[self.key] - path.x_1[self.key]) * real_mask.unsqueeze(-1)
        loss = torch.sum(err**2, dim=(-1, -2)) / (n_tokens * err.shape[-1] + eps)

        if self.time_factor:
            loss = loss * self.time_factor(path.t[self.key])

        if compute_stats:
            binned_losses = split_losses_by_time(path.t[self.key], loss, 5)
            stats_dict = {
                **{f"{self.key}_loss_bin_{i}": loss for i, loss in enumerate(binned_losses)},
            }
        else:
            stats_dict = {}

        loss_mask = real_mask.any(-1)
        avg_loss = loss.sum() / (loss_mask.sum() + eps)

        total_loss = avg_loss * self.loss_weight
        return total_loss, stats_dict

    @typecheck
    def step(self, batch_t: TensorDict, pred: TensorDict, t: TensorDict, dt: TensorDict) -> Tensor:
        """Deterministic forward-Euler step for continuous modalities.

        Args:
            batch_t: TensorDict containing the current sample at time `t`.
            pred: Model prediction (same layout as `batch_t`) used to compute the
                velocity field.
            t: TensorDict `(B,)` with current times.
            dt: TensorDict of step sizes to advance.

        Returns:
            Updated data tensor corresponding to time `t + dt`.
        """
        t = t[self.key].unsqueeze(-1).unsqueeze(-1)
        dt = dt[self.key].unsqueeze(-1).unsqueeze(-1)
        assert (
            dt.shape == t.shape == (batch_t[self.key].shape[0], 1, 1)
        ), f"t shape: {t.shape}, dt shape: {dt.shape}, batch_t shape: {batch_t[self.key].shape}"

        x1_pred = pred[self.key]
        velocity = (x1_pred - batch_t[self.key]) / (1 - t)

        x_new = batch_t[self.key] + velocity * dt
        x_new = self.mask_fn(x_new, batch_t[self.key_pad_mask])

        assert (
            x_new.shape == batch_t[self.key].shape
        ), f"x_new shape: {x_new.shape} != {batch_t[self.key].shape}"

        return x_new


class SDEMetricInterpolant(CenteredMetricInterpolant):
    """CenteredMetricInterpolant with Langevin/SDE-style sampling based on the Proteina paper.

    Args:
        langevin_sampling_schedule: Function that returns the sampling schedule for the score.
        white_noise_sampling_scale: Standard deviation of the sampled white noise.
        **kwargs: Forwarded to `Interpolant.__init__`.
    """

    @typecheck
    def __init__(
        self,
        langevin_sampling_schedule: Callable | None = None,
        white_noise_sampling_scale: float = 1.0,
        **kwargs,
    ):
        super().__init__(**kwargs)
        self.mse_loss = nn.MSELoss(reduction="none")
        self.white_noise_sampling_scale = white_noise_sampling_scale

        if langevin_sampling_schedule is None:
            self.langevin_sampling_schedule = lambda t: torch.zeros_like(t)
        else:
            self.langevin_sampling_schedule = langevin_sampling_schedule

    @typecheck
    def calculate_score(self, v_t: Tensor, x_t: Tensor, t: Tensor) -> Tensor:
        """
        Return the diffusion score `(t * v_t - x_t) / (1 - t)` as used in Proteina.

        Args:
            v_t: Velocity at time t.
            x_t: Position at time t.
            t: Time tensor.

        Returns:
            Score tensor.
        """
        return (t * v_t - x_t) / (1 - t + 1e-6)

    @typecheck
    def step(self, batch_t: TensorDict, pred: TensorDict, t: TensorDict, dt: TensorDict) -> Tensor:
        """Forward Euler integration step with score components and white noise injection.

        Args:
            batch_t: TensorDict containing the current sample at time `t`.
            pred: Model prediction (same layout as `batch_t`) used to compute the
                velocity field.
            t: TensorDict `(B,)` with current times.
            dt: TensorDict of step sizes to advance.

        Returns:
            Updated data tensor corresponding to time `t + dt`.
        """
        t = t[self.key].unsqueeze(-1).unsqueeze(-1)
        dt = dt[self.key].unsqueeze(-1).unsqueeze(-1)
        assert (
            dt.shape == t.shape == (batch_t[self.key].shape[0], 1, 1)
        ), f"t shape: {t.shape}, dt shape: {dt.shape}, batch_t shape: {batch_t[self.key].shape}"

        x1_pred = pred[self.key]
        velocity = (x1_pred - batch_t[self.key]) / (1 - t)

        score = self.calculate_score(velocity, batch_t[self.key], t)

        component_score = self.langevin_sampling_schedule(t) * score

        wiener_noise_scale = torch.sqrt(
            2 * self.langevin_sampling_schedule(t) * self.white_noise_sampling_scale
        ) * torch.randn_like(batch_t[self.key])
        white_noise = (
            self.sample_noise(batch_t[self.key].shape, batch_t[self.key_pad_mask])
            * wiener_noise_scale
        )

        x_new = batch_t[self.key] + velocity * dt + component_score * dt + white_noise * dt
        x_new = self.mask_fn(x_new, batch_t[self.key_pad_mask])

        # assert (
        #     x_new.shape == batch_t[self.key].shape
        # ), f"x_new shape: {x_new.shape} != {batch_t[self.key].shape}"

        return x_new


class MultimodalInterpolant:
    """Multimodal interpolant for flow matching.

    Constructs noisy samples from clean samples during training.

    Args:
        disc_feats: List of discrete feature names to corrupt.
        cont_feats: List of continuous feature names to corrupt.
        cont_feats_distributions: List of distributions for continuous features.
        mask_token_index: Index of the mask token.
        min_t: Minimum time step to sample during training.
        max_t: Maximum time step to sample during training.
        corrupt: Whether to corrupt samples during training.
        device: Device to run on.
        disc_interpolant_type: Type of discrete interpolant to use.

    NOTE: Adapted from https://github.com/jasonkyuyim/multiflow.
    """

    def __init__(
        self,
        disc_feats: List[str],
        cont_feats: List[str],
        cont_feats_distributions: List[Literal["centered_gaussian", "gaussian", "uniform"]],
        mask_token_index: int,
        max_num_nodes: int | None = None,
        min_t: float = 1e-2,
        max_t: float = 1.0,
        corrupt: bool = True,
        device: str | torch.device = "cpu",
        disc_interpolant_type: Literal["uniform", "masking"] = "masking",
    ):
        self.disc_feats = set(disc_feats)
        self.cont_feats = set(cont_feats)
        self.mask_token_index = mask_token_index
        self.max_num_nodes = max_num_nodes
        self.min_t = min_t
        self.max_t = max_t
        self.corrupt = corrupt
        self.device = device
        self.disc_interpolant_type = disc_interpolant_type

        self.feats = disc_feats + cont_feats
        self.num_tokens = mask_token_index + int(corrupt)  # +1 for the mask token if corrupting

        # Validate continuous feature distributions
        assert len(cont_feats) == len(
            cont_feats_distributions
        ), "Length of `cont_feats` must match length of `cont_feats_distributions`."
        assert all(
            dist in ("centered_gaussian", "gaussian", "uniform")
            for dist in cont_feats_distributions
        ), f"Invalid distribution ({cont_feats_distributions}) in `cont_feats_distributions`."
        self.cont_feat_to_distribution = dict(zip(cont_feats, cont_feats_distributions))

        # NOTE: To corrupt fractional coordinates (`frac_coords`), atom positions (`pos`) must be corrupted first
        assert len(self.feats) > 0, "No features to corrupt."
        self.feats.sort(reverse=True)

    @typecheck
    def _sample_t(self, batch_size: int) -> torch.Tensor:
        """Sample a time `t` uniformly from [min_t, max_t]."""
        t = torch.rand(batch_size, device=self.device)
        return t * (self.max_t - self.min_t) + self.min_t

    @typecheck
    def _gaussian(
        self, batch_size: int, num_tokens: int, emb_dim: int = 3, center: bool = True
    ) -> torch.Tensor:
        """Sample from a Gaussian distribution."""
        noise = torch.randn(batch_size, num_tokens, emb_dim, device=self.device)
        return noise - torch.mean(noise, dim=-2, keepdims=True) if center else noise

    @typecheck
    def _corrupt_disc_x(
        self,
        x_1: torch.Tensor,
        t: torch.Tensor,
        token_mask: torch.Tensor,
        diffuse_mask: torch.Tensor,
    ) -> torch.Tensor:
        """Corrupt the discrete input tensor `x_1` using the noise schedule defined by `t`."""
        batch_size, num_tokens = token_mask.shape

        assert x_1.shape == (
            batch_size,
            num_tokens,
        ), f"Expected x_1 to be of shape {(batch_size, num_tokens)}, but got: {x_1.shape}"
        assert t.shape == (
            batch_size,
            1,
        ), f"Expected t to be of shape {(batch_size, 1)}, but got: {t.shape}"
        assert token_mask.shape == (
            batch_size,
            num_tokens,
        ), f"Expected token_mask to be of shape {(batch_size, num_tokens)}, but got: {token_mask.shape}"
        assert diffuse_mask.shape == (
            batch_size,
            num_tokens,
        ), f"Expected diffuse_mask to be of shape {(batch_size, num_tokens)}, but got: {diffuse_mask.shape}"

        u = torch.rand(batch_size, num_tokens, device=self.device)
        x_t = x_1.clone()

        corruption_mask = u < (1 - t)  # [B, N]

        if self.disc_interpolant_type == "masking":
            x_t[corruption_mask] = self.mask_token_index

            x_t = x_t * token_mask + self.mask_token_index * (1 - token_mask)

        elif self.disc_interpolant_type == "uniform":
            uniform_sample = torch.randint_like(x_t, low=0, high=self.num_tokens)
            x_t[corruption_mask] = uniform_sample[corruption_mask]

            x_t = x_t * token_mask + self.mask_token_index * (1 - token_mask)

        else:
            raise ValueError(f"Unknown discrete interpolant type {self.disc_interpolant_type}")

        return x_t * diffuse_mask + x_1 * (1 - diffuse_mask)

    @typecheck
    def _corrupt_cont_x(
        self,
        x_1: torch.Tensor,
        t: torch.Tensor,
        token_mask: torch.Tensor,
        diffuse_mask: torch.Tensor,
        feat: str,
    ) -> torch.Tensor:
        """Corrupt the continuous input tensor `x_1` using the noise schedule defined by `t`."""
        distribution = self.cont_feat_to_distribution[feat]
        x_0 = (
            torch.rand_like(x_1)
            if distribution == "uniform"
            else self._gaussian(*x_1.shape, center=(distribution == "centered_gaussian"))
        )
        x_t = (1 - t[..., None]) * x_0 + t[..., None] * x_1
        x_t = x_t * diffuse_mask[..., None] + x_1 * (~diffuse_mask[..., None])
        return x_t * token_mask[..., None]

    @typecheck
    def corrupt_batch(self, batch: Batch) -> Batch:
        """Corrupt a batch of data by sampling a time `t` and interpolating to noisy samples.

        Args:
            batch: Batch of clean data with the following keys:
                - atom_types (torch.Tensor): Clean (discrete) atom types tensor.
                - pos (torch.Tensor): Clean (continuous) atom positions tensor.
                - frac_coords (torch.Tensor): Clean (continuous) fractional coordinates tensor.
                - lengths_scaled (torch.Tensor): Lattice lengths tensor, after scaling by `num_atoms**(1/3)`.
                - angles_radians (torch.Tensor): Lattice angles tensor, in radians.
                - batch (torch.Tensor): Batch node index tensor.

        Returns:
            Noisy batch of data with updated (or new) values for the following keys:
                - atom_types (torch.Tensor): Noisy (discrete) atom types tensor.
                - pos (torch.Tensor): Noisy (continuous) atom positions tensor.
                - frac_coords (torch.Tensor): Noisy (continuous) fractional coordinates tensor.
                - lengths_scaled (torch.Tensor): Noisy (continuous) lattice lengths tensor.
                - angles_radians (torch.Tensor): Noisy (continuous) lattice angles tensor.
                - token_mask (torch.Tensor): Token mask tensor.
        """
        assert all(feat in batch for feat in self.feats), (
            f"Batch must contain at least the following features: {self.feats}, "
            f"but got: {list(batch.keys())}"
        )

        noisy_batch = copy.deepcopy(batch)

        # Corrupt features according to their data modality
        # (i.e., discrete or `disc` and continuous or `cont`)
        for feat in self.feats:
            # [B, N, d]
            x_1 = batch[feat]

            # Convert from PyG batch to dense batch (potentially with fixed-length max padding to stabilize GPU memory usage)
            is_global_feat = x_1.shape[0] == batch.batch_size
            x_1, mask = (
                (
                    # NOTE: Global features do not need to be densely padded
                    x_1.unsqueeze(-2),
                    torch.ones((batch.batch_size, 1), device=self.device, dtype=torch.bool),
                )
                if is_global_feat
                else to_dense_batch(x_1, batch["batch"], max_num_nodes=self.max_num_nodes)
            )

            # [B, N]
            token_mask = diffuse_mask = mask
            batch_size, _ = token_mask.shape

            # [B, 1]
            t = self._sample_t(batch_size)[:, None]
            noisy_batch[f"{feat}_t"] = t

            # Apply discrete data corruptions
            if self.corrupt and feat in self.disc_feats:
                assert x_1.dtype in (torch.int16, torch.int32, torch.int64), (
                    f"Expected {feat} to be of dtype int16, int32 or int64, "
                    f"but got: {x_1.dtype}"
                )
                x_t = self._corrupt_disc_x(x_1, t, token_mask.long(), diffuse_mask.long())

            # Apply continuous data corruptions
            elif self.corrupt and feat in self.cont_feats:
                assert x_1.dtype in (
                    torch.float16,
                    torch.bfloat16,
                    torch.float32,
                    torch.float64,
                ), (
                    f"Expected {feat} to be of dtype float16, bfloat16, float32 or float64, "
                    f"but got: {x_1.dtype}"
                )
                x_t = self._corrupt_cont_x(x_1, t, token_mask, diffuse_mask, feat)

            # Skip corruptions
            else:
                x_t = x_1

            if torch.any(torch.isnan(x_t)):
                raise ValueError(f"NaN found in `x_t` during corruption of `{feat}`.")

            noisy_batch[feat] = x_t

            if (
                not is_global_feat
            ):  # NOTE: Global feature masks are placeholders and can be ignored from this point forward
                noisy_batch["token_mask"] = (
                    mask | noisy_batch["token_mask"] if "token_mask" in noisy_batch else mask
                )

        # Return batch of corrupted features
        return noisy_batch

    def __repr__(self) -> str:
        """Return a string representation of the interpolant."""
        return f"{self.__class__.__name__}(min_t={self.min_t}, max_t={self.max_t}, corrupt={self.corrupt})"
